{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11074869,"sourceType":"datasetVersion","datasetId":6902069},{"sourceId":11075267,"sourceType":"datasetVersion","datasetId":6902365},{"sourceId":11075642,"sourceType":"datasetVersion","datasetId":6902657}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, LSTM, Flatten, TimeDistributed\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\n# Dataset path\ndata_path = \"/kaggle/input/wrosely58\"\n\n# Verify the dataset path and list files\nif not os.path.exists(data_path):\n    raise FileNotFoundError(f\"The path {data_path} does not exist.\")\n\nprint(\"Files in the dataset directory:\")\nfiles = os.listdir(data_path)\nprint(files)\n\n# Load and combine all CSV files into a single DataFrame\nall_data = []\nfor file in files:\n    if file.endswith(\".csv\"):\n        file_path = os.path.join(data_path, file)\n        df = pd.read_csv(file_path)\n        all_data.append(df)\n\n# Combine all data into a single DataFrame\ncombined_data = pd.concat(all_data, axis=0, ignore_index=True)\n\n# Display dataset information\nprint(\"Combined data shape:\", combined_data.shape)\nprint(\"Combined data columns:\", combined_data.columns)\n\n# Drop the 'timestamp' column (non-numeric)\nif 'timestamp' in combined_data.columns:\n    combined_data = combined_data.drop(columns=['timestamp'])\n\n# Identify the label column\nlabel_column = 'label'  # Update this to the correct column name for labels\nif label_column not in combined_data.columns:\n    raise KeyError(f\"Column '{label_column}' not found in the dataset. Available columns: {combined_data.columns}\")\n\n# Separate features (X) and labels (y)\nX = combined_data.drop(columns=[label_column]).values\ny = combined_data[label_column].values\n\n# Encode labels to integers\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n\n# Normalize the data\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Reshape data for CNN-LSTM input (samples, timesteps, features)\n# Assuming each sample has 128 timesteps and 6 features (e.g., back_x, back_y, back_z, thigh_x, thigh_y, thigh_z)\ntimesteps = 128\nfeatures = X.shape[1]\nX = X.reshape(-1, timesteps, features)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Build CNN-LSTM model\nmodel = Sequential()\n\n# CNN layers\nmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None, timesteps, features)))\nmodel.add(TimeDistributed(MaxPooling1D(pool_size=2)))\nmodel.add(TimeDistributed(Conv1D(filters=128, kernel_size=3, activation='relu')))\nmodel.add(TimeDistributed(MaxPooling1D(pool_size=2)))\nmodel.add(TimeDistributed(Flatten()))\n\n# LSTM layer\nmodel.add(LSTM(100, return_sequences=False))\nmodel.add(Dropout(0.5))\n\n# Fully connected layer\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Output layer\nmodel.add(Dense(len(label_encoder.classes_), activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\n# Save the model\nmodel.save(\"cnn_lstm_har_model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T13:33:47.773451Z","iopub.execute_input":"2025-03-18T13:33:47.773807Z","iopub.status.idle":"2025-03-18T13:33:48.395066Z","shell.execute_reply.started":"2025-03-18T13:33:47.773780Z","shell.execute_reply":"2025-03-18T13:33:48.393878Z"}},"outputs":[{"name":"stdout","text":"Files in the dataset directory:\n['train.csv', 'test.csv']\nCombined data shape: (5150, 563)\nCombined data columns: Index(['rn', 'activity', 'tBodyAcc.mean.X', 'tBodyAcc.mean.Y',\n       'tBodyAcc.mean.Z', 'tBodyAcc.std.X', 'tBodyAcc.std.Y', 'tBodyAcc.std.Z',\n       'tBodyAcc.mad.X', 'tBodyAcc.mad.Y',\n       ...\n       'fBodyBodyGyroJerkMag.meanFreq', 'fBodyBodyGyroJerkMag.skewness',\n       'fBodyBodyGyroJerkMag.kurtosis', 'angle.tBodyAccMean.gravity',\n       'angle.tBodyAccJerkMean.gravityMean', 'angle.tBodyGyroMean.gravityMean',\n       'angle.tBodyGyroJerkMean.gravityMean', 'angle.X.gravityMean',\n       'angle.Y.gravityMean', 'angle.Z.gravityMean'],\n      dtype='object', length=563)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-dca61b57f04a>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mlabel_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'label'\u001b[0m  \u001b[0;31m# Update this to the correct column name for labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel_column\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column '{label_column}' not found in the dataset. Available columns: {combined_data.columns}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Separate features (X) and labels (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"Column 'label' not found in the dataset. Available columns: Index(['rn', 'activity', 'tBodyAcc.mean.X', 'tBodyAcc.mean.Y',\\n       'tBodyAcc.mean.Z', 'tBodyAcc.std.X', 'tBodyAcc.std.Y', 'tBodyAcc.std.Z',\\n       'tBodyAcc.mad.X', 'tBodyAcc.mad.Y',\\n       ...\\n       'fBodyBodyGyroJerkMag.meanFreq', 'fBodyBodyGyroJerkMag.skewness',\\n       'fBodyBodyGyroJerkMag.kurtosis', 'angle.tBodyAccMean.gravity',\\n       'angle.tBodyAccJerkMean.gravityMean', 'angle.tBodyGyroMean.gravityMean',\\n       'angle.tBodyGyroJerkMean.gravityMean', 'angle.X.gravityMean',\\n       'angle.Y.gravityMean', 'angle.Z.gravityMean'],\\n      dtype='object', length=563)\""],"ename":"KeyError","evalue":"\"Column 'label' not found in the dataset. Available columns: Index(['rn', 'activity', 'tBodyAcc.mean.X', 'tBodyAcc.mean.Y',\\n       'tBodyAcc.mean.Z', 'tBodyAcc.std.X', 'tBodyAcc.std.Y', 'tBodyAcc.std.Z',\\n       'tBodyAcc.mad.X', 'tBodyAcc.mad.Y',\\n       ...\\n       'fBodyBodyGyroJerkMag.meanFreq', 'fBodyBodyGyroJerkMag.skewness',\\n       'fBodyBodyGyroJerkMag.kurtosis', 'angle.tBodyAccMean.gravity',\\n       'angle.tBodyAccJerkMean.gravityMean', 'angle.tBodyGyroMean.gravityMean',\\n       'angle.tBodyGyroJerkMean.gravityMean', 'angle.X.gravityMean',\\n       'angle.Y.gravityMean', 'angle.Z.gravityMean'],\\n      dtype='object', length=563)\"","output_type":"error"}],"execution_count":30}]}